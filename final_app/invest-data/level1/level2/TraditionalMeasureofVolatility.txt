 Traditional Measure of Volatility . Most investors know that standard deviation is the typical statistic used to measure volatility. Standard deviation is simply defined as the square root of the average variance of the data from its mean. While this statistic is relatively easy to calculate, the assumptions behind its interpretation are more complex, which in turn raises concern about its accuracy. As a result, there is a certain level of skepticism surrounding its validity as an accurate measure of risk. In order for standard deviation to be an accurate measure of risk, an assumption has to be made that investment performance data follows a normal distribution. In graphical terms, a normal distribution of data will plot on a chart in a manner that looks like a bell-shaped curve. If this standard holds true, then approximately 68% of the expected outcomes should lie between ±1 standard deviations from the investment's expected return, 95% should lie between ±2 standard deviations, and 99.7% should lie between ±3 standard deviations. For example, during the period of June 1, 1979, through June 1, 2009, the three-year rolling annualized average performance of the S&P 500 Index was 9.5%, and its standard deviation was 10%. Given these baseline parameters of performance, one would expect that 68% of the time the expected performance of the S&P 500 index would fall within a range of -0.5% and 19.5% (9.5% ±10%). Unfortunately, there are three main reasons why investment performance data may not be normally distributed. First, investment performance is typically skewed, which means that return distributions are typically asymmetrical. As a result, investors tend to experience abnormally high and low periods of performance. Second, investment performance typically exhibits a property known as kurtosis, which means that investment performance exhibits an abnormally large number of positive and/or negative periods of performance. Taken together, these problems warp the look of the bell-shaped curve, and distort the accuracy of standard deviation as a measure of risk. In addition to skewness and kurtosis, a problem known as heteroskedasticity is also a cause for concern. Heteroskedasticity simply means that the variance of the sample investment performance data is not constant over time. As a result, standard deviation tends to fluctuate based on the length of the time period used to make the calculation, or the period of time selected to make the calculation.